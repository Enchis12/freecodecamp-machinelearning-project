{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1rRo8oNqZ-Rj"},"outputs":[],"source":["# Import libraries. You may or may not use all of these.\n","!pip install -q git+https://github.com/tensorflow/docs\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import tensorflow_docs as tfdocs\n","import tensorflow_docs.plots\n","import tensorflow_docs.modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiX2FI4gZtTt"},"outputs":[],"source":["# Import data\n","!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n","dataset = pd.read_csv('insurance.csv')\n","dataset.tail()"]},{"cell_type":"code","source":["# Make NumPy printouts easier to read.\n","np.set_printoptions(precision=3, suppress=True)"],"metadata":{"id":"y78YKSLRYjrx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert categorical data into numerical data\n","dataset['sex'] = pd.factorize(dataset['sex'])[0]\n","dataset['smoker'] = pd.factorize(dataset['smoker'])[0]\n","dataset['region'] = pd.factorize(dataset['region'])[0]\n","\n","dataset.tail()"],"metadata":{"id":"zFLQPv1WMETm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the data into 80% for training and 20% for testing\n","train_feature = dataset.sample(frac=0.8, random_state=42)\n","test_feature = dataset.drop(train_feature.index)"],"metadata":{"id":"OzPaMwI9BaNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make expenses as the label and other as feature\n","train_dataset = train_feature.copy()\n","test_dataset = test_feature.copy()\n","\n","train_labels = train_dataset.pop('expenses')\n","test_labels = test_dataset.pop('expenses')"],"metadata":{"id":"HhBhro1iB2fK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the normalizer layer and the model\n","normalizer = tf.keras.layers.Normalization(axis=-1)\n","normalizer.adapt(np.array(train_dataset))\n","\n","model = keras.Sequential([\n","    normalizer,\n","    layers.Dense(4, activation='relu'),\n","    layers.Dense(2, activation='relu'),\n","    layers.Dense(1),\n","])"],"metadata":{"id":"HNGGr8_Lanu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compiling the model\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n","    loss='mae',\n","    metrics=['mae', 'mse'])\n","\n","model.build()"],"metadata":{"id":"TWqjYZw5N02a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training phase\n","%%time\n","history = model.fit(\n","    train_dataset,\n","    train_labels,\n","    epochs=100,\n","    # Suppress logging.\n","    verbose=0,\n","    # Calculate validation results on 20% of the training data.\n","    validation_split = 0.2)"],"metadata":{"collapsed":true,"id":"OScegi-xOfAB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"L5hV_Pmrb3iB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hist = pd.DataFrame(history.history)\n","hist['epoch'] = history.epoch\n","hist"],"metadata":{"id":"D9o3EHfDPDFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_loss(history):\n","  plt.plot(history.history['loss'], label='loss')\n","  plt.plot(history.history['val_loss'], label='val_loss')\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Error [expenses]')\n","  plt.legend()\n","  plt.grid(True)"],"metadata":{"id":"S4SBZ_9kPLnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_loss(history)"],"metadata":{"id":"bpwW5PGJPQr2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xe7RXH3N3CWU"},"outputs":[],"source":["# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n","# Test model by checking how well the model generalizes using the test set.\n","loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n","\n","print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n","\n","if mae < 3500:\n","  print(\"You passed the challenge. Great job!\")\n","else:\n","  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n","\n","# Plot predictions.\n","test_predictions = model.predict(test_dataset).flatten()\n","\n","a = plt.axes(aspect='equal')\n","plt.scatter(test_labels, test_predictions)\n","plt.xlabel('True values (expenses)')\n","plt.ylabel('Predictions (expenses)')\n","lims = [0, 50000]\n","plt.xlim(lims)\n","plt.ylim(lims)\n","_ = plt.plot(lims,lims)\n"]},{"cell_type":"markdown","source":["NB: as I experimented with the model, I found that the number of layers, how dense the layer is (a.k.a number of units), and the number of epochs is correlated (although not always :v) as listed below.\n","\n","- If you only use normalizer layer and output layer (layer.Dense(1)), you'll need a very high number of epochs.\n","- If you add one layer between normalizer and output, the number of epochs can be decreased but you have to increase the number of units.\n","- If you add more than one layer between normalizer and output, you can decrease both the number of epochs and the number of units"],"metadata":{"id":"0g-ravSmfQiX"}}],"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/freeCodeCamp/boilerplate-linear-regression-health-costs-calculator/blob/master/fcc_predict_health_costs_with_regression.ipynb","timestamp":1742132912774}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
